# 圖形識別第一次作業
## 資工碩一 611021234 林駿丞

### How I do the assignment
<B>1. 生成訓練及測試用的圖片：</B>  
  
為了蒐集為鴨子的pixel以及非鴨子pixel做機率模型，我在`generate_imgData.py`這份程式中先讀取full_duck.jpg，然後再隨機取這張圖片中的兩個500x500大小作為訓練圖片01duck.jpg，另一張再生成測試用的圖片(02duck.jpg~04duck.jpg)

01duck.jpg：
![](https://i.imgur.com/LMAgj8X.jpg)

02duck.jpg：
![](https://i.imgur.com/HhqTIwe.jpg)

03duck.jpg：
![](https://i.imgur.com/eZfEgyI.jpg)

04duck.jpg：
![](https://i.imgur.com/PB1mHSa.jpg)



<B>2. 生成訓練用的數值資料：</B>  
  
把這張訓練圖片01duck.jpg中R、G、B值分別大於特定值(最佳結果是220，稍後會說明)的pixel加上`1`的label(指該pixel值為鴨子pixel)，其餘的加上`0`的label，生成一個如下的DataFrame：

|| r | g | b | class|
| -------- | -------- | -------- | -------- |-------- |
| 0     | 147     | 156     |161 | 0
|1	|143	|152	|157	|0
|2	|151	|158	|164	|0
|3	|164	|171	|177	|0
|...|...|...|...|...
|249998	|128	|129|	133|	0
|249999	|127	|128|	132	|0

250000 rows × 4 columns
  
這時候來觀察類別分佈
`print('We have ', len(df[df['class'] == 1]), ' pixels are ducks.')
print('We have ', len(df[df['class'] == 0]), ' pixels are background.')`
輸出結果
`We have  44446  pixels are ducks.
We have  205554  pixels are background.`

<B>3. 將資料轉換成以類別分類的字典：</B>  
  
讓資料轉換成`{0:[[pixel_values]],1:[[pixel_values]]}`的形式，存在`generated_by_class`中。

<B>4. 再計算出兩個類別中，所有值所計算出來的平均值及標準差：</B>  
  
得到`{0: [(138.63476023955945, 49.95362346960297),
  (143.36737007114434, 51.11668513761753),
  (145.6915430684513, 53.597159209486534)],
 1: [(252.218438538206, 1.309799084429091),
  (254.1594684385382, 1.1697254057048527),
  (254.9717607973422, 0.24965069801883422)]}`的結果，存於`dist`變數中。
  
<B>5. 定義計算高斯機率密度函數為函式`probabilty`：</B>  
  
已知高斯機率密度函數公式為：

![](https://i.imgur.com/Z8BVD4u.jpg)

我們將其轉換為程式碼，列在`main.py`的`probabilty`方便利用。

<B>6. 撰寫預測函式`predict`：</B> 

在這段中，我們計算被預測資料傳入函式後，會與平均值及標準差一同被傳入於第6步產生的函式，並且計算出隸屬於兩個類別的機率，最後再回傳最有可能的類別。

<B>7. 讀取要預測的圖片：</B> 

讀取要預測的圖片，測試時為02~04duck.jpg，實際預測為full_duck.jpg。並將圖片三個通道的每個pixel值儲存成一個二維陣列`test_data`，將pixel位置額外存成一個二維陣列`test_pos`。並以迴圈送入`predict`。

<B>8. 生成預測結果的圖片：</B>

最後根據預測得到的每個像素類別以及在`test_pos`中所儲存的像素位置，生成一個將背景變黑，鴨子變白的圖片`result.jpg`。


### The results I got
result02.jpg:
![](https://i.imgur.com/cMFwqoo.jpg)


result03.jpg:
![](https://i.imgur.com/ExvSQ3v.jpg)

result04.jpg:
![](https://i.imgur.com/DmLFA34.jpg)


full_result.jpg:
![](https://i.imgur.com/wmqFqKd.jpg)



### Discussions on the results

<B>1. 設定類別時的門檻值：</B>

第一個最直觀受到影響的因素是在第2步將訓練圖片轉換成數值及增加標籤時，所設定的pixel值門檻，最一開始我所設定的值是250，若r, g, b三個value都大於250才能視為是鴨子pixel，但以這個門檻產生的資料集進行預測，得到的圖片有許多鴨子內部的pixel被當成背景移除掉了，以同樣是02duck.jpg為例，結果如下：

`We have  1636  pixels are ducks.
We have  248364  pixels are background.`

![](https://i.imgur.com/NxIcVPT.jpg)

當將門檻值設定為240時如下：

`We have  12120  pixels are ducks.
We have  237880  pixels are background.`
![](https://i.imgur.com/anFx8Sk.jpg)

比起前一張已經好很多了，因此反覆嘗試繼續往下調整到220：

`We have  34901  pixels are ducks.
We have  215099  pixels are background.`
![](https://i.imgur.com/5mDhA8y.jpg)

會得到一個比較滿意的結果。


<b>2. 使用不同的照片訓練：</b>

我們所用來訓練的照片01duck.jpg是一張看起來鴨子與背景分布較為平均的照片，但若使用不同的照片來進行訓練的話，結果會有所不同嗎？

這次我們以02duck.jpg作為訓練照片，04duck.jpg做預測，在其他參數不變的情況下，拿來與01duck.jpg作為訓練照片產生的結果做對比：

以01duck.jpg進行預測的：
`We have  34901  pixels are ducks.
We have  215099  pixels are background.`
![](https://i.imgur.com/yc74jry.jpg)


以02duck.jpg進行預測的：
`We have  13366  pixels are ducks.
We have  236634  pixels are background.`

![](https://i.imgur.com/T6egvgn.jpg)

從這邊可以看到，以不同照片作為機率模型建立資料的差別，02duck.jpg的效果也不錯，甚至有更優於01duck.jpg的趨勢，而且從class分佈的數量來看，不一定兩類之間的數量越多，效果就越準確。

### Summary
這項作業讓我了解貝氏分類器以及高斯機率密度函數的運作，不同於過往在機器學習領域使用套件去辨識圖片或者單純用影像處理工具來擷取出特定元素的方法，雖然這樣的方式對於處理這項問題並不是最快的方法，但這樣的方式讓人更能理解機率模型的運作。

在整份作業中，我先隨機生成訓練及測試用的圖片若干張，然後在選定建立機率模型的圖片後，將其轉成純數值的資料集型態。之後使用程式碼實作出高斯機率密度函數的機率模型，並且計算出訓練資料中各通道的標準差及平均值，最後讀入測試圖片，送入預測用的函數進行預測，並再生成預測後的圖片。

而以得到的結果來看，在label訓練資料的過程中，表現最好的門檻值為220，所生成的結果，雖然會多一點噪點，但鴨子的部分會比較清楚。而以不同的照片進行訓練的話，結果上也會不同，並且訓練圖片中兩類pixel的多寡越平均，不一定會造成比較好的結果。